{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADR (Anomaly Detection by workflow Relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Software systems usually generate logs for troubleshooting. The logs are text messages recording system events, which can help engineers determine the system's runtime status. \n",
    "\n",
    "ADR employs matrix nullspace to mine numerical relations from log data and the mined relations can be used for both offline and online anomaly detection and facilitate fault diagnosis. ADR starts by parsing the raw logs into structured log events. Then the parsed log events are grouped into sequences by sessions or sliding windows. For each session or window, the occurrences of its log events are counted, resulting in the event-count-matrix. Then the available numerical relations are extracted from the event-count-matrix by evaluating its nullspace. Finally, the extracted relations are used to detect abnormal log sequences in the offline or online manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following parts, we use the BGL logs as example to show the capability of ADR.\n",
    "\n",
    "For ease of presentation, the raw BGL logs are already parsed into structured log events and saved in _data/Drain_result_ (The raw data is parsed by Drain <sup>[1]</sup>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline anomaly detection at session level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=====BGL dataset=====\nprecision, recall, f1, mcc for testing set:\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.9408, 1.0, 0.9695, 0.9372821480127299)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from ADR.preprocess import *\n",
    "from ADR.ADR import *\n",
    "\n",
    "log_path = Path(r'data\\Drain_result\\bgl_10k\\ECM_sessions_10k.npz')\n",
    "X_Y = np.load(log_path)\n",
    "x, y = X_Y['df_X'], X_Y['df_Y']\n",
    "train_size = 361\n",
    "x_train, y_train, x_test, y_test = split_to_train_test_by_num(x, y, train_size)\n",
    "\n",
    "model = ADR(1, add_parity=True, add_tf=True)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(\"=====BGL dataset=====\")\n",
    "print('precision, recall, f1, mcc for testing set:')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online anomaly detection at entry level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Use PSO to find the optimal window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from ADR import pso_window_size\n",
    "pso_window_size.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Split the logs to windows and detect anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "==========\nwindow size is 53\nfitting the model...\n(this step may take long, but it only needs to be run one time to obtain the relations that are used for following anomaly detection)\ngrouping logs to windows...\nanomaly detection...\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "shapes (0,1) and (1153,1139) not aligned: 1 (dim 1) != 1153 (dim 0)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-988d8ebdbb7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'(this step may take long, but it only needs to be run one time to obtain the relations that are used for following anomaly detection)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_bgl_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_EventIds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_bgl_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Projects\\000PhD\\SRDS2020_pub_code\\ADR\\ADR\\ADR_Online.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, test_df_logs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mextended_npa_event_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextend_2darray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpa_event_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighest_degree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhighest_degree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_parity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_parity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_tf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_tf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mdot_prod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextended_npa_event_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mns_extended_ECM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__abs__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdot_prod\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1e-10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp_r_f_mcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpa_bLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (0,1) and (1153,1139) not aligned: 1 (dim 1) != 1153 (dim 0)"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bgl_sample_path = Path(r'data\\Drain_result\\bgl_10k\\BGL.log_structured500k.csv')\n",
    "bgl_template_path = Path(r'data\\Drain_result\\bgl_10k\\BGL.log_templates.csv')\n",
    "\n",
    "df_bgl_sample = pd.read_csv(bgl_sample_path, sep=',', header=0)\n",
    "df_bgl_sample[\"bLabel\"] = 1\n",
    "df_bgl_sample.loc[df_bgl_sample[\"Label\"]==\"-\", \"bLabel\"] = 0\n",
    "\n",
    "# split the logs by number windows\n",
    "from ADR.ADR_Online import *\n",
    "\n",
    "list_EventIds = pd.read_csv(bgl_template_path, header=0)[\"EventId\"].to_list()\n",
    "df_logs = df_bgl_sample.iloc[0:100000, :]\n",
    "\n",
    "train_ratio = 0.7\n",
    "num_train = int(df_logs.shape[0] * train_ratio)\n",
    "\n",
    "df_bgl_train = df_logs.iloc[0:num_train, :]\n",
    "df_bgl_test = df_logs.iloc[num_train:, :]\n",
    "\n",
    "window_size = 53\n",
    "print('='*10)\n",
    "print(f'window size is {window_size}')\n",
    "model = ADR_Online(window_size=window_size, highest_degree=1, add_parity=True, add_tf=True)\n",
    "print('fitting the model...')\n",
    "print('(this step may take long, but it only needs to be run one time to obtain the relations that are used for following anomaly detection)')\n",
    "model.fit(df_bgl_train, list_EventIds)\n",
    "model.evaluate(df_bgl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] P. He, J. Zhu, Z. Zheng, and M. R. Lyu, “Drain: An Online Log Parsing Approach with Fixed Depth Tree,” in 2017 IEEE International Conference on Web Services (ICWS), Jun. 2017, pp. 33–40, doi: 10.1109/ICWS.2017.13."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}