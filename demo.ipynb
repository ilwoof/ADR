{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADR (Anomaly Detection by workflow Relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADR mines numerical relations from log data and uses the relations for anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following parts, we use the BGL logs as example to show the capability of ADR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of presentation, the raw BGL logs are already parsed into structured log events by Drain <sup>[1]</sup> and the event-count-matrices are evaluated and saved in \"_data.zip_\". Please unzip \"_data.zip_\" to ADR folder before running the demo code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T14:47:14.214918Z",
     "start_time": "2021-04-26T14:47:14.203239Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "log_paths = {'hdfs': 'data/Drain_result/hdfs/x_y_xColumns.npz',\n",
    "             'bgl': 'data/Drain_result/bgl/x_y_xColumns.npz',\n",
    "             'hd': 'data/Drain_result/Hadoop/x_y_xColumns.npz',\n",
    "             'spirit':'data/Drain_result/spirit/x_y_xColumns.npz'}\n",
    "\n",
    "log_datasets = {}\n",
    "for name, log_path in log_paths.items():\n",
    "    log_datasets[name] = np.load(log_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sADR (supervised, need labelled logs for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T13:59:18.654504Z",
     "start_time": "2021-04-26T13:59:18.638851Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8ce367afed69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m350\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m450\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlog_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_y_xColumns\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlog_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'====={log_name}====='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxColumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_y_xColumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_y_xColumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_y_xColumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xColumns'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_datasets' is not defined"
     ]
    }
   ],
   "source": [
    "from ADR import preprocess\n",
    "from ADR import sADR\n",
    "\n",
    "train_numbers = [100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "\n",
    "for log_name, x_y_xColumns in log_datasets.items():\n",
    "    print(f'====={log_name}=====')\n",
    "    x, y, xColumns = x_y_xColumns['x'], x_y_xColumns['y'], x_y_xColumns['xColumns']\n",
    "\n",
    "    for i in range(len(train_numbers)):\n",
    "        train_number = train_numbers[i]\n",
    "        print(f'-----train number:{train_number}-----')\n",
    "        if i == 0:\n",
    "            x_train, y_train, x_test, y_test = x_train, y_train, x_test, y_test = preprocess.split_to_train_test_by_num(x, y, num_train=train_number)\n",
    "        else:\n",
    "            x_train_adding, y_train_adding, x_test, y_test = preprocess.split_to_train_test_by_num(x, y, num_train=train_numbers[i]-train_numbers[i-1])\n",
    "            x_train = np.concatenate((x_train, x_train_adding), axis=0)\n",
    "            y_train = np.concatenate((y_train, y_train_adding), axis=0)\n",
    "\n",
    "        model = sADR.sADR()\n",
    "        model.fit(x_train, y_train)\n",
    "        precision, recall, f1 = model.evaluate(x_train, y_train)\n",
    "        print('Accuracy on training set:')\n",
    "        print(f\"precision, recall, f1: {[precision, recall, f1]}\")\n",
    "\n",
    "        precision, recall, f1 = model.evaluate(x_test, y_test)\n",
    "        print('Accuracy on testing set:')\n",
    "        print(f\"precision, recall, f1: {[precision, recall, f1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uADR (unsupervised, do not need labelled logs for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T14:47:21.074112Z",
     "start_time": "2021-04-26T14:47:18.011598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "hdfs\n",
      "x shape: (575061, 48)\n",
      "x_train shape:(287530, 48)\n",
      "x_test shape:(287531, 48)\n",
      "========\n",
      "bgl\n",
      "x shape: (69252, 384)\n",
      "x_train shape:(34626, 384)\n",
      "x_test shape:(34626, 384)\n",
      "========\n",
      "hd\n",
      "x shape: (55, 347)\n",
      "x_train shape:(27, 347)\n",
      "x_test shape:(28, 347)\n",
      "========\n",
      "spirit\n",
      "x shape: (517, 988)\n",
      "x_train shape:(258, 988)\n",
      "x_test shape:(259, 988)\n"
     ]
    }
   ],
   "source": [
    "from ADR import preprocess\n",
    "\n",
    "u_log_datasets_train_test = {}\n",
    "\n",
    "u_train_ratios = {'hdfs': 0.5,\n",
    "                'bgl': 0.5,\n",
    "                'hd': 0.5,\n",
    "                'spirit': 0.5}\n",
    "for name, x_y_xColumns in log_datasets.items():\n",
    "    if name in ['hdfs', 'bgl', 'hd', 'spirit']:\n",
    "        print(\"========\")\n",
    "        print(name)\n",
    "        x, y, xColumns = x_y_xColumns['x'], x_y_xColumns['y'], x_y_xColumns['xColumns']\n",
    "        print(f'x shape: {x.shape}')\n",
    "        x_train, y_train, x_test, y_test = preprocess.split_to_train_test_by_ratio(x, y, train_ratio=u_train_ratios[name])\n",
    "        u_log_datasets_train_test[name] = [x_train, y_train, x_test, y_test]\n",
    "        print(f'x_train shape:{x_train.shape}')\n",
    "        print(f'x_test shape:{x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T23:45:39.484694Z",
     "start_time": "2021-04-26T14:47:38.051739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====hdfs=====\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [0.1252, 1.0, 0.2226]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.1292, 1.0, 0.2289]\n",
      "=====bgl=====\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [0.6615, 1.0, 0.7962]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.6598, 1.0, 0.795]\n",
      "=====hd=====\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [0.85, 0.7391, 0.7907]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.75, 1.0, 0.8571]\n",
      "=====spirit=====\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [0.2248, 1.0, 0.3671]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.2201, 1.0, 0.3608]\n"
     ]
    }
   ],
   "source": [
    "from ADR import uADR\n",
    "\n",
    "estimated_pN = 0.5\n",
    "\n",
    "for log_name in u_log_datasets_train_test:\n",
    "    print(f'====={log_name}=====')\n",
    "    x_train, y_train, x_test, y_test = u_log_datasets_train_test[log_name]\n",
    "\n",
    "    model = uADR.uADR(AN_ratio=1-estimated_pN, nrows_per_sample=10, nrounds=100)\n",
    "    model.fit(x_train)\n",
    "    precision, recall, f1 = model.evaluate(x_train, y_train)\n",
    "    print('Accuracy on training set:')\n",
    "    print(f\"precision, recall, f1: {[precision, recall, f1]}\")\n",
    "\n",
    "    precision, recall, f1 = model.evaluate(x_test, y_test)\n",
    "    print('Accuracy on testing set:')\n",
    "    print(f\"precision, recall, f1: {[precision, recall, f1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T00:40:28.002492Z",
     "start_time": "2021-04-27T00:40:27.282258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.2201, 1.0, 0.3608]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1 = model.evaluate(x_test, y_test)\n",
    "print('Accuracy on testing set:')\n",
    "print(f\"precision, recall, f1: {[precision, recall, f1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T01:05:42.460557Z",
     "start_time": "2021-04-27T01:03:26.951330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====bgl=====\n",
      "-----0.7-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [0.7552, 0.6972, 0.7251]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.7532, 0.6949, 0.7229]\n"
     ]
    }
   ],
   "source": [
    "from ADR import uADR\n",
    "\n",
    "list_estimated_pN = [0.7]\n",
    "\n",
    "for log_name in u_log_datasets_train_test:\n",
    "    if log_name == 'bgl':\n",
    "        for estimated_pN in list_estimated_pN:\n",
    "            print(f'====={log_name}=====')\n",
    "            print(f'-----{estimated_pN}-----')\n",
    "            x_train, y_train, x_test, y_test = u_log_datasets_train_test[log_name]\n",
    "\n",
    "            model = uADR.uADR(AN_ratio=1-estimated_pN, nrows_per_sample=10, nrounds=100)\n",
    "            model.fit(x_train)\n",
    "            precision, recall, f1 = model.evaluate(x_train, y_train)\n",
    "            print('Accuracy on training set:')\n",
    "            print(f\"precision, recall, f1: {[precision, recall, f1]}\")\n",
    "\n",
    "            precision, recall, f1 = model.evaluate(x_test, y_test)\n",
    "            print('Accuracy on testing set:')\n",
    "            print(f\"precision, recall, f1: {[precision, recall, f1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T02:00:06.800166Z",
     "start_time": "2021-04-27T01:49:45.925436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====bgl=====\n",
      "-----0.6-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [0.6837, 0.991, 0.8092]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.6815, 0.9908, 0.8076]\n"
     ]
    }
   ],
   "source": [
    "from ADR import uADR\n",
    "\n",
    "list_estimated_pN = [0.6]\n",
    "\n",
    "for log_name in u_log_datasets_train_test:\n",
    "    if log_name == 'bgl':\n",
    "        for estimated_pN in list_estimated_pN:\n",
    "            print(f'====={log_name}=====')\n",
    "            print(f'-----{estimated_pN}-----')\n",
    "            x_train, y_train, x_test, y_test = u_log_datasets_train_test[log_name]\n",
    "\n",
    "            model = uADR.uADR(AN_ratio=1-estimated_pN, nrows_per_sample=10, nrounds=100)\n",
    "            model.fit(x_train)\n",
    "            precision, recall, f1 = model.evaluate(x_train, y_train)\n",
    "            print('Accuracy on training set:')\n",
    "            print(f\"precision, recall, f1: {[precision, recall, f1]}\")\n",
    "\n",
    "            precision, recall, f1 = model.evaluate(x_test, y_test)\n",
    "            print('Accuracy on testing set:')\n",
    "            print(f\"precision, recall, f1: {[precision, recall, f1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T02:27:59.266768Z",
     "start_time": "2021-04-27T02:27:59.150081Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/Drain_result/bgl/bgl_uADR_model_0p6.pkl', 'wb') as class_file:\n",
    "    pickle.dump(model, class_file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T02:30:15.844752Z",
     "start_time": "2021-04-27T02:30:14.807245Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/Drain_result/bgl/bgl_uADR_model_0p6.pkl', 'rb') as input:\n",
    "    model = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T02:30:28.565952Z",
     "start_time": "2021-04-27T02:30:27.248962Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ECM = pd.read_csv('data/Drain_result/bgl/bgl_sessions_ECM.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T02:39:19.647244Z",
     "start_time": "2021-04-27T02:39:19.641694Z"
    }
   },
   "outputs": [],
   "source": [
    "bgl_x_part1 = df_ECM.values[:35000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T02:39:22.046159Z",
     "start_time": "2021-04-27T02:39:22.038801Z"
    }
   },
   "outputs": [],
   "source": [
    "bgl_x_part2 = df_ECM.values[35000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T02:40:12.705833Z",
     "start_time": "2021-04-27T02:39:47.084378Z"
    }
   },
   "outputs": [],
   "source": [
    "bgl_y_predict_part1 = model.predict(bgl_x_part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T02:40:36.921509Z",
     "start_time": "2021-04-27T02:40:12.832972Z"
    }
   },
   "outputs": [],
   "source": [
    "bgl_y_predict_part2 = model.predict(bgl_x_part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T02:40:51.296185Z",
     "start_time": "2021-04-27T02:40:51.291410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33027"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgl_y_predict_part1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T02:40:58.652236Z",
     "start_time": "2021-04-27T02:40:58.647152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12516"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgl_y_predict_part2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T02:44:09.370393Z",
     "start_time": "2021-04-27T02:44:09.368047Z"
    }
   },
   "outputs": [],
   "source": [
    "bgl_predict_y = np.concatenate([bgl_y_predict_part1, bgl_y_predict_part2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T02:44:14.412307Z",
     "start_time": "2021-04-27T02:44:14.407701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69252,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgl_predict_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T02:48:35.802403Z",
     "start_time": "2021-04-27T02:48:35.796386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['R23-M0-N0-C:J09-U11', 'R23-M0-N0-C:J15-U11', 'R23-M0-N0-C:J11-U11',\n",
       "       'R23-M0-N0-C:J13-U11', 'R23-M0-N0-C:J17-U11', 'R23-M0-N0-C:J03-U01',\n",
       "       'R23-M0-N0-C:J05-U11', 'R23-M0-N0-C:J03-U11', 'R23-M0-N0-C:J07-U11',\n",
       "       'R23-M0-N0-C:J15-U01',\n",
       "       ...\n",
       "       'R54-M0-N8-C:J10-U11', 'R54-M0-N8-C:J06-U11', 'R54-M0-N8-C:J14-U01',\n",
       "       'R54-M0-N8-C:J10-U01', 'R54-M0-N8-C:J08-U01', 'R54-M0-N8-C:J04-U01',\n",
       "       'R54-M0-N8-C:J06-U01', 'R54-M0-N8-C:J04-U11', 'R54-M0-N8-C:J02-U01',\n",
       "       'R54-M0-N8-C:J02-U11'],\n",
       "      dtype='object', length=23709)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ECM.index[~bgl_predict_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T02:51:44.789864Z",
     "start_time": "2021-04-27T02:51:44.653406Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt('data/Drain_result/bgl/ADR0p6_predict_y.csv', bgl_predict_y, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] P. He, J. Zhu, Z. Zheng, and M. R. Lyu, “Drain: An Online Log Parsing Approach with Fixed Depth Tree,” in 2017 IEEE International Conference on Web Services (ICWS), Jun. 2017, pp. 33–40, doi: 10.1109/ICWS.2017.13."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "812.85px",
    "left": "1559px",
    "right": "20px",
    "top": "117px",
    "width": "341px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}