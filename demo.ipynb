{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADR (Anomaly Detection by workflow Relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADR mines numerical relations from log data and uses the relations for anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following parts, we use the BGL logs as example to show the capability of ADR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of presentation, the raw BGL logs are already parsed into structured log events by Drain <sup>[1]</sup> and the event-count-matrices are evaluated and saved in \"_data.zip_\". Please unzip \"_data.zip_\" to ADR folder before running the demo code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T07:57:47.271848Z",
     "start_time": "2021-04-25T07:57:47.259604Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "log_paths = {'hdfs': 'data/Drain_result/hdfs/x_y_xColumns.npz',\n",
    "             'bgl': 'data/Drain_result/bgl/x_y_xColumns.npz',\n",
    "             'hd': 'data/Drain_result/Hadoop/x_y_xColumns.npz',\n",
    "             'spirit':'data/Drain_result/spirit/x_y_xColumns.npz'}\n",
    "\n",
    "log_datasets = {}\n",
    "for name, log_path in log_paths.items():\n",
    "    log_datasets[name] = np.load(log_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sADR (supervised, need labelled logs for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====hdfs=====\n",
      "-----train number:100-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8933, 1.0, 0.9437]\n",
      "-----train number:150-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8933, 1.0, 0.9437]\n",
      "-----train number:200-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8933, 1.0, 0.9437]\n",
      "-----train number:250-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8934, 1.0, 0.9437]\n",
      "-----train number:300-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8933, 1.0, 0.9437]\n",
      "-----train number:350-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8934, 1.0, 0.9437]\n",
      "-----train number:400-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8934, 1.0, 0.9437]\n",
      "-----train number:450-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8933, 1.0, 0.9437]\n",
      "-----train number:500-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8933, 1.0, 0.9437]\n",
      "=====bgl=====\n",
      "-----train number:100-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8328, 1.0, 0.9087]\n",
      "-----train number:150-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8726, 1.0, 0.932]\n",
      "-----train number:200-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8937, 1.0, 0.9439]\n",
      "-----train number:250-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8974, 1.0, 0.9459]\n",
      "-----train number:300-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8974, 1.0, 0.9459]\n",
      "-----train number:350-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8974, 1.0, 0.9459]\n",
      "-----train number:400-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.9138, 1.0, 0.9549]\n",
      "-----train number:450-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.9203, 1.0, 0.9585]\n",
      "-----train number:500-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.9227, 1.0, 0.9598]\n",
      "=====hd=====\n",
      "-----train number:100-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.0, 0.0, 0.0]\n",
      "-----train number:150-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "-----train number:200-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "-----train number:250-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "-----train number:300-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "-----train number:350-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "-----train number:400-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "-----train number:450-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "-----train number:500-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "=====spirit=====\n",
      "/home/bolz/miniconda3/envs/python373/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bolz/miniconda3/envs/python373/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "-----train number:100-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.6718, 1.0, 0.8037]\n",
      "-----train number:150-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.7626, 1.0, 0.8653]\n",
      "-----train number:200-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.7984, 1.0, 0.8879]\n",
      "-----train number:250-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.808, 1.0, 0.8938]\n",
      "-----train number:300-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.811, 1.0, 0.8957]\n",
      "-----train number:350-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [0.9886, 1.0, 0.9943]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8226, 1.0, 0.9027]\n",
      "-----train number:400-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [0.9792, 1.0, 0.9895]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8308, 1.0, 0.9076]\n",
      "-----train number:450-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [1.0, 1.0, 1.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.876, 1.0, 0.9339]\n",
      "-----train number:500-----\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [0.9829, 1.0, 0.9914]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8655, 1.0, 0.9279]\n"
     ]
    }
   ],
   "source": [
    "from ADR import preprocess\n",
    "from ADR import sADR\n",
    "\n",
    "train_numbers = [100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "\n",
    "for log_name, x_y_xColumns in log_datasets.items():\n",
    "    print(f'====={log_name}=====')\n",
    "    x, y, xColumns = x_y_xColumns['x'], x_y_xColumns['y'], x_y_xColumns['xColumns']\n",
    "\n",
    "    for i in range(len(train_numbers)):\n",
    "        train_number = train_numbers[i]\n",
    "        print(f'-----train number:{train_number}-----')\n",
    "        if i == 0:\n",
    "            x_train, y_train, x_test, y_test = x_train, y_train, x_test, y_test = preprocess.split_to_train_test_by_num(x, y, num_train=train_number)\n",
    "        else:\n",
    "            x_train_adding, y_train_adding, x_test, y_test = preprocess.split_to_train_test_by_num(x, y, num_train=train_numbers[i]-train_numbers[i-1])\n",
    "            x_train = np.concatenate((x_train, x_train_adding), axis=0)\n",
    "            y_train = np.concatenate((y_train, y_train_adding), axis=0)\n",
    "\n",
    "        model = sADR.sADR()\n",
    "        model.fit(x_train, y_train)\n",
    "        precision, recall, f1 = model.evaluate(x_train, y_train)\n",
    "        print('Accuracy on training set:')\n",
    "        print(f\"precision, recall, f1: {[precision, recall, f1]}\")\n",
    "\n",
    "        precision, recall, f1 = model.evaluate(x_test, y_test)\n",
    "        print('Accuracy on testing set:')\n",
    "        print(f\"precision, recall, f1: {[precision, recall, f1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uADR (unsupervised, do not need labelled logs for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T07:57:53.971288Z",
     "start_time": "2021-04-25T07:57:51.310261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "hdfs\n",
      "x shape: (575061, 48)\n",
      "x_train shape:(287530, 48)\n",
      "x_test shape:(287531, 48)\n",
      "========\n",
      "bgl\n",
      "x shape: (69252, 384)\n",
      "x_train shape:(34626, 384)\n",
      "x_test shape:(34626, 384)\n",
      "========\n",
      "hd\n",
      "x shape: (55, 347)\n",
      "x_train shape:(27, 347)\n",
      "x_test shape:(28, 347)\n",
      "========\n",
      "spirit\n",
      "x shape: (517, 988)\n",
      "x_train shape:(258, 988)\n",
      "x_test shape:(259, 988)\n"
     ]
    }
   ],
   "source": [
    "from ADR import preprocess\n",
    "\n",
    "u_log_datasets_train_test = {}\n",
    "\n",
    "u_train_ratios = {'hdfs': 0.5,\n",
    "                'bgl': 0.5,\n",
    "                'hd': 0.5,\n",
    "                'spirit': 0.5}\n",
    "for name, x_y_xColumns in log_datasets.items():\n",
    "    if name in ['hdfs', 'bgl', 'hd', 'spirit']:\n",
    "        print(\"========\")\n",
    "        print(name)\n",
    "        x, y, xColumns = x_y_xColumns['x'], x_y_xColumns['y'], x_y_xColumns['xColumns']\n",
    "        print(f'x shape: {x.shape}')\n",
    "        x_train, y_train, x_test, y_test = preprocess.split_to_train_test_by_ratio(x, y, train_ratio=u_train_ratios[name])\n",
    "        u_log_datasets_train_test[name] = [x_train, y_train, x_test, y_test]\n",
    "        print(f'x_train shape:{x_train.shape}')\n",
    "        print(f'x_test shape:{x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T08:00:48.034599Z",
     "start_time": "2021-04-25T07:58:06.390411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====hdfs=====\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [0.8941, 1.0, 0.9441]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.8926, 1.0, 0.9433]\n",
      "=====bgl=====\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [0.7088, 0.5568, 0.6237]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.7152, 0.5648, 0.6311]\n",
      "=====hd=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bolz/miniconda3/envs/python373/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "precision, recall, f1: [0.0, 0.0, 0.0]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.75, 1.0, 0.8571]\n",
      "=====spirit=====\n",
      "Accuracy on training set:\n",
      "precision, recall, f1: [0.2431, 1.0, 0.3912]\n",
      "Accuracy on testing set:\n",
      "precision, recall, f1: [0.2046, 1.0, 0.3397]\n"
     ]
    }
   ],
   "source": [
    "from ADR import uADR\n",
    "\n",
    "estimated_pN = 0.9\n",
    "\n",
    "for log_name in u_log_datasets_train_test:\n",
    "    print(f'====={log_name}=====')\n",
    "    x_train, y_train, x_test, y_test = u_log_datasets_train_test[log_name]\n",
    "\n",
    "    model = uADR.uADR(AN_ratio=1-estimated_pN, nrows_per_sample=10, nrounds=100)\n",
    "    model.fit(x_train)\n",
    "    precision, recall, f1 = model.evaluate(x_train, y_train)\n",
    "    print('Accuracy on training set:')\n",
    "    print(f\"precision, recall, f1: {[precision, recall, f1]}\")\n",
    "\n",
    "    precision, recall, f1 = model.evaluate(x_test, y_test)\n",
    "    print('Accuracy on testing set:')\n",
    "    print(f\"precision, recall, f1: {[precision, recall, f1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] P. He, J. Zhu, Z. Zheng, and M. R. Lyu, “Drain: An Online Log Parsing Approach with Fixed Depth Tree,” in 2017 IEEE International Conference on Web Services (ICWS), Jun. 2017, pp. 33–40, doi: 10.1109/ICWS.2017.13."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "507.85px",
    "left": "1559px",
    "right": "20px",
    "top": "120px",
    "width": "341px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}